<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="不足为奇"><title>代码随笔丨Soft Rank：排序微分的解决之道 | IFwhale</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 7.1.1"></head><body><div class="body_container"><div id="header"><div class="site-name"><a id="logo" href="/.">IFwhale</a><p class="description">个人工作学习生活记录</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home">首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tags"> 标签</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">代码随笔丨Soft Rank：排序微分的解决之道</h1><div class="post-meta">2024-10-23<span> · </span><span class="category"><a href="/categories/Coding/">Coding</a></span></div><a class="disqus-comment-count" href="/posts/af905acf/#waline"><span class="waline-comment-count" id="/posts/af905acf/"></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E6%83%85%E6%8F%90%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">前情提要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Soft-Rank-%E7%AE%80%E4%BB%8B"><span class="toc-number">2.</span> <span class="toc-text">Soft Rank 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Soft-Rank-%E5%BA%94%E7%94%A8"><span class="toc-number">3.</span> <span class="toc-text">Soft Rank 应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-1%EF%BC%9ASoft-Rank-%E7%9B%B4%E6%8E%A5%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.</span> <span class="toc-text">方法 1：Soft Rank 直接实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-2%EF%BC%9Afast-soft-sort-by-Google-Research"><span class="toc-number">3.2.</span> <span class="toc-text">方法 2：fast-soft-sort by Google Research</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83"><span class="toc-number">4.</span> <span class="toc-text">方法比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Soft-Rank-%E5%8F%82%E6%95%B0"><span class="toc-number">5.</span> <span class="toc-text">Soft Rank 参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E5%8F%82%E6%95%B0%E4%B8%8B%E4%BC%B0%E8%AE%A1%E5%87%86%E7%A1%AE%E7%A8%8B%E5%BA%A6%E5%AF%B9%E6%AF%94"><span class="toc-number">5.1.</span> <span class="toc-text">不同参数下估计准确程度对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E5%8F%82%E6%95%B0%E4%B8%8B-Rank-IC-%E6%A2%AF%E5%BA%A6%E5%AF%B9%E6%AF%94"><span class="toc-number">5.2.</span> <span class="toc-text">不同参数下 Rank IC 梯度对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="post-content"><h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><p>在做金融时序收益率预测时，尤其在需要按照分位数来选择标的回测的情况下，我们可能会希望使用 <a target="_blank" rel="noopener" href="https://bbs.quantclass.cn/thread/23991">Rank IC</a>（可理解为秩相关性）作为评价收益率预测能力的标准。然而在深度学习中，这一指标却无法直接作为损失函数使用，因为反向传播要求损失函数的计算是可微的，而 rank 计算却是不可微分的。</p><p>为了解决这一问题，Soft Rank 算法应运而生。</p><h2 id="Soft-Rank-简介"><a href="#Soft-Rank-简介" class="headerlink" title="Soft Rank 简介"></a>Soft Rank 简介</h2><p>以我的理解，Soft Rank 算法是一种近似算法， 能够在允许一定误差的情况下给出一个数列的 rank 值。比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">ts = torch.randn(<span class="number">1</span>, <span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original data:\n&quot;</span>, ts)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Rank of data:\n&quot;</span>, torch.tensor(rankdata(ts.detach().numpy()), dtype=torch.float32))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Soft ranked data:\n&quot;</span>, soft_rank(ts, regularization_strength=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Original data:</span></span><br><span class="line"><span class="string"> tensor([[-0.2936,  1.3017, -0.7662,  1.9435, -1.1154, -0.4187,  1.0562,  0.8975,</span></span><br><span class="line"><span class="string">         -1.7620,  1.5031]], requires_grad=True)</span></span><br><span class="line"><span class="string">Rank of data:</span></span><br><span class="line"><span class="string"> tensor([ 5.,  8.,  3., 10.,  2.,  4.,  7.,  6.,  1.,  9.])</span></span><br><span class="line"><span class="string">Soft ranked data:</span></span><br><span class="line"><span class="string"> tensor([[ 5.,  8.,  3., 10.,  2.,  4.,  7.,  6.,  1.,  9.]],</span></span><br><span class="line"><span class="string">       grad_fn=&lt;StackBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>可以看到，<code>soft_rank</code> 函数输出的值是近似于真实 rank 的，同时它还保留了 <code>Tensor</code> 的梯度信息，便于进行反向传播运算。</p><h2 id="Soft-Rank-应用"><a href="#Soft-Rank-应用" class="headerlink" title="Soft Rank 应用"></a>Soft Rank 应用</h2><p>接下来介绍两种我接触过的 Soft Rank 算法实践。</p><h3 id="方法-1：Soft-Rank-直接实现"><a href="#方法-1：Soft-Rank-直接实现" class="headerlink" title="方法 1：Soft Rank 直接实现"></a>方法 1：Soft Rank 直接实现</h3><p>以下给出直接用 <code>PtTorch</code> 原生方法实现 Soft Rank 的算法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">soft_rank</span>(<span class="params">y, regularization_strength=<span class="number">1.0</span></span>):</span><br><span class="line">    <span class="comment"># 计算所有 pairwise 差异，形状为 (n, n)</span></span><br><span class="line">    pairwise_diff = y.t() - y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用 sigmoid 函数</span></span><br><span class="line">    sigmoid_vals = torch.sigmoid(pairwise_diff / regularization_strength)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个元素的 soft rank</span></span><br><span class="line">    ranks = sigmoid_vals.<span class="built_in">sum</span>(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 标准化</span></span><br><span class="line">    <span class="keyword">return</span> ranks / y.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>注意这一函数最终输出的结果与真正的 Rank 分布可能有很大差异，比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">ts = torch.randn(<span class="number">1</span>, <span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original data:\n&quot;</span>, ts)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Rank of data:\n&quot;</span>, torch.tensor(rankdata(ts.detach().numpy()), dtype=torch.float32))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Soft ranked data:\n&quot;</span>, soft_rank(ts, regularization_strength=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Original data:</span></span><br><span class="line"><span class="string"> tensor([[-0.7919,  2.1005, -0.8140, -0.0836,  0.7290,  0.5838,  0.9163, -0.0866,</span></span><br><span class="line"><span class="string">          1.0455,  0.7178]], requires_grad=True)</span></span><br><span class="line"><span class="string">Rank of data:</span></span><br><span class="line"><span class="string"> tensor([ 2., 10.,  1.,  4.,  7.,  5.,  8.,  3.,  9.,  6.])</span></span><br><span class="line"><span class="string">Soft ranked data:</span></span><br><span class="line"><span class="string"> tensor([1.5000, 9.5000, 0.5000, 3.4509, 6.5000, 4.5000, 7.5000, 2.5491, 8.5000,</span></span><br><span class="line"><span class="string">        5.5000], grad_fn=&lt;DivBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p>不过这一差异对于相关性的计算没有任何影响。</p><h3 id="方法-2：fast-soft-sort-by-Google-Research"><a href="#方法-2：fast-soft-sort-by-Google-Research" class="headerlink" title="方法 2：fast-soft-sort by Google Research"></a>方法 2：<code>fast-soft-sort</code> by Google Research</h3><p>凭借 Google 对 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2002.08871">Fast Differentiable Sorting and Ranking</a> 的研究和开发，我们有了可以直接调用的 Soft Sort 和Soft Rank 的工具：<a target="_blank" rel="noopener" href="https://github.com/google-research/fast-soft-sort?tab=readme-ov-file"><code>fast-soft-sort</code></a>。使用方式相当简单：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fast_soft_sort.pytorch_ops <span class="keyword">import</span> soft_rank</span><br><span class="line"></span><br><span class="line">ts = torch.randn(<span class="number">1</span>, <span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Soft ranked data:\n&quot;</span>, soft_rank(ts, regularization_strength=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Soft ranked data:</span></span><br><span class="line"><span class="string"> tensor([5.5000, 3.5000, 6.5000, 1.5000, 4.5000, 7.5000, 2.5000, 8.5000, 0.5000,</span></span><br><span class="line"><span class="string">        9.5000], grad_fn=&lt;DivBackward0&gt;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h2 id="方法比较"><a href="#方法比较" class="headerlink" title="方法比较"></a>方法比较</h2><p>从性能上看，方法 2 远超 方法 1。</p><p><code>fast-soft-sort</code> 的时间复杂度为 $O(n\log{n})$，空间复杂度为 $O(n)$，而直接实现的函数时间复杂度和空间复杂度都是 $O(n^2)$。实践上看也的确如此，当数列长度大于 5000 时，两者性能差异就已经很明显了，这里就不进一步测试了。</p><p>当然，方法 1 也不是没有优点，它直接使用 PyTorch 内置方法实现，无需引入其他库。另外，<code>fast-soft-sort</code> 底层算法使用 NumPy 实现，因此必须先将 <code>Tensor</code> 通过 <code>.cpu()</code> 转移到 CPU 上进行计算，再转移回 GPU 中，这也会带来一定的性能消耗。好在，也有人实现了 <a target="_blank" rel="noopener" href="https://github.com/teddykoker/torchsort">Torchsort</a>，它采用了和 <code>fast-soft-sort</code> 相同的算法，但是使用 PyTorch 内置方法实现。我没有使用过这一工具，感兴趣的读者可以自行尝试。</p><h2 id="Soft-Rank-参数"><a href="#Soft-Rank-参数" class="headerlink" title="Soft Rank 参数"></a>Soft Rank 参数</h2><p>你可能注意到，两种方法都存在 <code>regularization_strength</code> 这一参数。这个参数的效果如下：</p><table><thead><tr><th>优缺点</th><th>参数较大时</th><th>参数较小时</th></tr></thead><tbody><tr><td>优点</td><td>相关系数梯度较大，可能更容易收敛</td><td>rank 值估算更精确，秩相关系数误差较小</td></tr><tr><td>缺点</td><td>rank 值估算更粗糙，秩相关系数误差较大</td><td>相关系数梯度较小，可能不容易收敛</td></tr></tbody></table><p>且在参数不变的情况下，样本量增大同样会导致估计精确程度的下降。但是估计精度仅仅是对于 soft rank 后数值的分布而言。无论参数如何，soft rank 后数值的顺序都是完全正确的。</p><h3 id="不同参数下估计准确程度对比"><a href="#不同参数下估计准确程度对比" class="headerlink" title="不同参数下估计准确程度对比"></a>不同参数下估计准确程度对比</h3><p>首先，生成两组随机数据进行测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定样本数量</span></span><br><span class="line">num_samples = <span class="number">5000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 均值</span></span><br><span class="line">mu = np.array([<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 协方差矩阵</span></span><br><span class="line">r = np.array([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">0.5</span>],</span><br><span class="line">    [<span class="number">0.5</span>, <span class="number">1</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用相关函数，生成随机数</span></span><br><span class="line">rng = np.random.default_rng()</span><br><span class="line">y = rng.multivariate_normal(mu, r, size=num_samples)</span><br><span class="line"></span><br><span class="line">y_true = torch.tensor(y[:, <span class="number">0</span>], dtype=torch.float32, requires_grad=<span class="literal">True</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y_pred = torch.tensor(y[:, <span class="number">1</span>], dtype=torch.float32, requires_grad=<span class="literal">True</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>此时，两组数据分布如下：</p><p><img src="/posts/af905acf/image-20241023204947513.png" alt="两组数列分布图"></p><p>以下两图展示了在不同参数下，同一组数据使用 <code>soft_rank</code> 计算的结果与精确计算 rank 的结果的相关性：</p><p><img src="/posts/af905acf/image-20241023205011669.png" alt="不同参数下，估算值与精确值相关性展示"></p><p>此时，在我预设的数据下，计算出来的相关系数为</p><table><thead><tr><th>精确 Rank IC</th><th>参数为 0.001 时 Soft Rank IC</th><th>参数为 0.0001 时 Soft Rank IC</th></tr></thead><tbody><tr><td>0.46844181418418884</td><td>0.4764254093170166</td><td>0.46844363212585</td></tr></tbody></table><h3 id="不同参数下-Rank-IC-梯度对比"><a href="#不同参数下-Rank-IC-梯度对比" class="headerlink" title="不同参数下 Rank IC 梯度对比"></a>不同参数下 Rank IC 梯度对比</h3><p>下图绘制了当 <code>regularization_strength</code> 分别取值为 0.001 和 0.0001 的情况下，以及直接计算 IC（而非 Rank IC）的情况下，IC 的梯度向量中数值的分布，并标注了每个分布的 25% 和 75% 分位的位置。</p><p><img src="/posts/af905acf/image-20241023205213659.png" alt="不同参数下以及 IC 计算后梯度向量数值分布"></p><p>可以看到，当 <code>regularization_strength</code> 取值为 0.001 时，梯度向量中数值的分布与直接计算 IC 相似，但当取值为 0.0001 时，梯度向量中数值除了少数离散值以外，数量级都很小，以至于 25% 和 75% 分位线都无法分辨。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul><li>相比方法 1，方法 2 的复杂度远远更低，从性能角度考虑，如果没有特别需求，建议使用方法 2。</li><li><code>regularization_strength</code> 除了影响估算精度以外，也会影响梯度的分布。实际应用时，应当充分考虑两边的利弊来调整参数。</li></ul></div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Soft-Rank/" rel="tag">Soft Rank</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%B7%A5%E5%85%B7/" rel="tag">工具</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" rel="tag">损失函数</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul></div><div class="post-nav"><a class="pre" href="/posts/45d1c86e/">量化实习 v3丨Week 7 &amp; 8 过山车般的体验</a><a class="next" href="/posts/6a6a1b0a/">量化实习 v3丨Week 6：逐渐上手</a></div><div class="nofancybox" id="waline"></div><script src="//unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" type="text/css" href="//unpkg.com/@waline/client@v2/dist/waline.css"><script>let metaInfo=["nick","mail","link"],requiredMeta="nick".split(",").filter(e=>metaInfo.indexOf(e)>-1);Waline.init({el:"#waline",comment:!0,serverURL:"https://comment.ifwhale.top",pageSize:"30",wordLimit:"500",requiredMeta:requiredMeta,locale:{placeholder:"填写邮箱后，收到评论回复将会邮件通知~",sofa:"欢迎和我说说话~"}})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/img/avatar.jpg" alt="IFwhale"></a><p>不足为奇。</p><div class="info-icons"><a class="info-icon" href="mailto:ifwhale@outlook.com" title="Email" target="_blank"><i class="fa fa-envelope-square"></i></a><a class="info-icon" href="https://github.com/fwhale0" title="Github" target="_blank"> <i class="fa fa-github-square"></i></a><a class="info-icon" href="https://www.linkedin.com/in/%E8%B4%9D%E5%AE%81-%E5%88%98-176a78287/" title="Linkedin" target="_blank"> <i class="fa fa-linkedin-square"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank"> <i class="fa fa-rss-square"></i></a></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o">分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Coding/">Coding</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AF%B9%E8%AF%9D%E5%BD%95/">对话录</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BB%BA%E7%AB%99-SEO/">建站 & SEO</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%B5%8F%E9%98%85%E7%BA%AA/">赏阅纪</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93/">量化交易</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%87%8F%E5%8C%96%E5%AE%9E%E4%B9%A0%E6%97%A5%E8%AE%B0/">量化实习日记</a><span class="category-list-count">64</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%87%8F%E5%8C%96%E7%AC%94%E9%9D%A2%E8%AF%95/">量化笔面试</a><span class="category-list-count">3</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o">标签</i></div><div class="tagcloud"><a href="/tags/Quant/" style="font-size:15px">Quant</a> <a href="/tags/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/" style="font-size:15px">职业发展</a> <a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size:15px">工具</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size:15px">深度学习</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size:15px">损失函数</a> <a href="/tags/Soft-Rank/" style="font-size:15px">Soft Rank</a> <a href="/tags/%E5%BB%BA%E7%AB%99/" style="font-size:15px">建站</a> <a href="/tags/SEO/" style="font-size:15px">SEO</a> <a href="/tags/%E8%B5%84%E6%BA%90/" style="font-size:15px">资源</a> <a href="/tags/%E5%9B%9E%E6%B5%8B%E6%A1%86%E6%9E%B6/" style="font-size:15px">回测框架</a> <a href="/tags/%E9%9A%8F%E7%AC%94/" style="font-size:15px">随笔</a> <a href="/tags/%E5%BF%83%E6%83%85/" style="font-size:15px">心情</a> <a href="/tags/%E5%AE%9E%E4%B9%A0/" style="font-size:15px">实习</a> <a href="/tags/%E9%87%8F%E5%8C%96%E9%9D%A2%E8%AF%95%E7%BB%BF%E7%9A%AE%E4%B9%A6/" style="font-size:15px">量化面试绿皮书</a> <a href="/tags/Quant-Interview/" style="font-size:15px">Quant-Interview</a> <a href="/tags/%E6%97%A5%E8%AE%B0/" style="font-size:15px">日记</a> <a href="/tags/%E8%A1%8C%E4%B8%9A%E5%9F%BA%E6%9C%AC%E9%9D%A2/" style="font-size:15px">行业基本面</a> <a href="/tags/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" style="font-size:15px">阅读笔记</a> <a href="/tags/%E6%82%89%E8%BE%BE%E5%A4%9A/" style="font-size:15px">悉达多</a> <a href="/tags/%E6%B5%B7%E8%BE%B9%E7%9A%84%E5%8D%A1%E5%A4%AB%E5%8D%A1/" style="font-size:15px">海边的卡夫卡</a> <a href="/tags/%E9%A2%9D%E5%B0%94%E5%8F%A4%E7%BA%B3%E6%B2%B3%E5%8F%B3%E5%B2%B8/" style="font-size:15px">额尔古纳河右岸</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o">最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/posts/ed333396/">量化实习 v3丨Week 10：因子矿工再出发</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/75b0f34e/">量化实习 v3丨Week 9：特征归因</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/45d1c86e/">量化实习 v3丨Week 7 & 8 过山车般的体验</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/af905acf/">代码随笔丨Soft Rank：排序微分的解决之道</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/6a6a1b0a/">量化实习 v3丨Week 6：逐渐上手</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/42d27edd/">量化实习 v3丨Week 5：群策群力</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/d3610788/">量化实习 v3丨Week 4：深度幽灵</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/550011ce/">量化实习 v3丨Week 3：仍然没有适应</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/b8fcf2dc/">量化实习 v3丨Week 1 & 2：赶鸭子上架</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/d0a0c715/">阅读笔记丨《额尔古纳河右岸》——少数民族消亡史</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o">最近评论</i></div><div id="widget-waline-list"></div><script type="text/javascript" id="recent-comment" serverurl="https://comment.ifwhale.top" count="5" src="/js/recent-comments.js?v=1.0.0" async></script></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer"><div class="copyright">Copyright © 2023 - 2024 <a href="/." rel="nofollow">IFwhale</a></div><div class="license" xmlns:cc="http://creativecommons.org/ns#">Licensed under <a class="copyright-link" rel="nofollow license noopener noreferrer" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a><img class="copyright-logo" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img class="copyright-logo" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img class="copyright-logo" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img class="copyright-logo" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></div><div class="power">Powered by <a rel="nofollow" target="_blank" href="https://hexo.io">Hexo</a> & <a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo">Maupassant</a></div></div></div></div><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script><script type="text/javascript" src="/js/absolute-url.js?v=1.0.0"></script></div></body></html>